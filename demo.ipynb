{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=\"g\"\n",
    "\n",
    "from groq import Groq\n",
    "import instructor\n",
    "from instructor import Instructor\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from abc import ABC, abstractmethod\n",
    "import requests\n",
    "import fitz\n",
    "\n",
    "from prompts import DEFAULT_PROMPT, SYSTEM_PROMPT\n",
    "\n",
    "client = Groq(\n",
    "            api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    )\n",
    "\n",
    "logs = open(\"logs.txt\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReACT(BaseModel):\n",
    "    thought : str\n",
    "    action : str\n",
    "    action_input : str\n",
    "\n",
    "class Structurize():\n",
    "    def __init__(self,client, model):\n",
    "        self.patched_client = instructor.from_groq(client)\n",
    "        self.model = model\n",
    "        \n",
    "    def __call__(self, messages):\n",
    "        reply = self.patched_client.chat.completions.create(\n",
    "            model = self.model,\n",
    "            response_model = ReACT,\n",
    "            messages = [{\"role\": \"user\", \"content\": f\"Extract: {messages}\"}],\n",
    "        )\n",
    "        return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client, model, tools, max_steps=10):\n",
    "        self.client = client\n",
    "        self.max_steps = max_steps\n",
    "        self.model = model\n",
    "        self.history = []\n",
    "        self.tools = tools\n",
    "        self.structurizer = Structurize(client, model)\n",
    "        \n",
    "    def __call__(self, message):\n",
    "        for i in range(self.max_steps):\n",
    "            response = self.run(message)\n",
    "            # if response.action.lower() == \"finish\":\n",
    "            #     print(f\"THOUGHT : {response.thought}\\n\\nACTION : {response.action}\\n\\nACTION INPUT : {response.action_input}\",file=logs,flush=True)\n",
    "            #     print(\"Finished.\",file=logs,flush=True)\n",
    "            #     break\n",
    "            action = next((tool for tool in self.tools if response.action==tool.__class__.__name__.lower()),None)\n",
    "            if action is None:\n",
    "                print(f\"THOUGHT : {response.thought}\\n\\nACTION : {response.action}\\n\\nACTION INPUT : {response.action_input}\",file=logs,flush=True)\n",
    "                print(f\"Action {response.action} not found in tools.\")\n",
    "                print(f\"Action {response.action} not found in tools.\",file=logs,flush=True)\n",
    "                self.history.append(f\"THOUGHT : {response.thought}\\n\\nACTION : {response.action}\\n\\nACTION INPUT : {response.action_input}\")\n",
    "                break\n",
    "            observation = action.run(response.action_input)\n",
    "            self.history.append(f\"THOUGHT : {response.thought}\\n\\nACTION : {response.action}\\n\\nACTION INPUT : {response}\\n\\nOBSERVATION : {observation}\")\n",
    "            print(f\"THOUGHT : {response.thought}\\n\\nACTION : {response.action}\\n\\nACTION INPUT : {response.action_input}\\n\\nOBSERVATION : {observation}\",file=logs,flush=True)\n",
    "            if response.action.lower() == \"finish\":\n",
    "                print(\"Finished.\",file=logs,flush=True)\n",
    "                break\n",
    "            \n",
    "    def get_tool_desc(self):\n",
    "        return  \"\\n\".join([f\"{tool.__class__.__name__.lower()}: {tool.run.__doc__}\" for tool in self.tools])\n",
    "    \n",
    "    def run(self, query, max_retries=3):\n",
    "        for i in range(max_retries):\n",
    "            try:\n",
    "                prompt = DEFAULT_PROMPT.format(query=query, history=self.history, tool_descriptions=self.get_tool_desc())\n",
    "                output = self.client.chat.completions.create(\n",
    "                        messages=[\n",
    "                            {\n",
    "                                \"role\": \"system\",\n",
    "                                \"content\": SYSTEM_PROMPT,\n",
    "                            },\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": prompt,\n",
    "                            },\n",
    "                            \n",
    "                        ],\n",
    "                        model=self.model,\n",
    "                    ).choices[0].message.content\n",
    "                response = self.structurizer(output)\n",
    "                return response\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(e,file=logs,flush=True)\n",
    "                print(\"Retrying...\")\n",
    "                print(\"Retrying...\",file=logs,flush=True)\n",
    "                continue\n",
    "        print(\"Max retries exceeded.\")\n",
    "        print(\"Max retries exceeded.\",file=logs,flush=True)\n",
    "        return ReACT(\n",
    "            thought=\"\",\n",
    "            action=\"finish\",\n",
    "            action_input=\"\"\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for tools.\n",
    "\n",
    "    Methods:\n",
    "    run(input_params):\n",
    "    Abstract method to run the tool with given input parameters.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def run(self, input):\n",
    "        pass\n",
    "\n",
    "class Finish(Tool):\n",
    "    \"\"\"\n",
    "    A tool to return the final answer or result.\n",
    "\n",
    "    Methods:\n",
    "    run(final_answer):\n",
    "    Returns the final answer provided to it.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, final_answer):\n",
    "        \"\"\"\n",
    "        Returns the final answer provided to it.\n",
    "\n",
    "        Parameters:\n",
    "        final_answer : str\n",
    "        The final answer or result that needs to be returned.\n",
    "        Your final answer should always be either yes, no, before, after or a named entity.\n",
    "        **DO NOT ANSWER IN SENTENCE**\n",
    "\n",
    "        Returns:\n",
    "        final_answer : str\n",
    "        The same final answer or result.\n",
    "        \"\"\"\n",
    "        # print(\"Finish\")\n",
    "        try:\n",
    "            print(final_answer)\n",
    "            return final_answer\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\",file=logs,flush=True)\n",
    "            return f\"An error occurred: {e}\"\n",
    "    \n",
    "class AskUser(Tool):\n",
    "    \"\"\"\n",
    "    A tool that prompts the user for assistance in answering a query.\n",
    "\n",
    "    Methods:\n",
    "    run(query):\n",
    "    Prompts the user with a query to obtain user assistance.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, query):\n",
    "        \"\"\"\n",
    "        Prompts the user for help and awaits their input. Use this when the retrieved information is\n",
    "        not useful or whenever you need user assistance for further directions. DO NOT ask the user to analyse\n",
    "        the information or for the final answer. This tool is onl intended to get directions from the user\n",
    "\n",
    "        Parameters:\n",
    "        query : str\n",
    "        The query string that encapsulates the information or question needing a user response.\n",
    "\n",
    "        Returns:\n",
    "        response : str\n",
    "        The response provided by the user.\n",
    "        \"\"\"\n",
    "        # print(\"AskUser\")\n",
    "        try:\n",
    "            return input(query)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\",file=logs,flush=True)\n",
    "            return f\"An error occurred: {e}\"\n",
    "    \n",
    "class FetchPaper(Tool):\n",
    "    \"\"\"\n",
    "    A tool that fetches the research paper from the internet.\n",
    "\n",
    "    Methods:\n",
    "    run(arxiv_id):\n",
    "    Returns the path of the PDF.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, arxiv_id):\n",
    "        \"\"\"\n",
    "        Fetches the research paper from the internet using the provided arxiv ID.\n",
    "\n",
    "        Parameters:\n",
    "        arxiv_id : str\n",
    "        The arxiv ID of the research paper that needs to be fetched.\n",
    "        **DO NOT ask the user to analyse the information or for the final answer. This tool is onl intended to get directions from the user**\n",
    "\n",
    "        Returns:\n",
    "        path : str\n",
    "        The path to the PDF of the research paper.\n",
    "        \"\"\"\n",
    "        # print(\"FetchPaper\")\n",
    "        url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "        save_path = f\"{os.getcwd()}/Memory/{arxiv_id}.pdf\"\n",
    "        print(\"Downloading PDF from:\", url, file=logs,flush=True)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Check for request errors\n",
    "\n",
    "            with open(save_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "            return f\"Downloaded successfully to {save_path}\"\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error downloading PDF: {e}\", file=logs,flush=True)\n",
    "            return f\"Error downloading PDF: {e}\"\n",
    "            \n",
    "        \n",
    "class Parse(Tool):\n",
    "    \"\"\"\n",
    "    A tool that parses the PDF file and extracts the text from it.\n",
    "    Methods:\n",
    "    run(path):\n",
    "    Parses the PDF file and extracts the text from it.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, path):\n",
    "        \"\"\"\n",
    "        Reads the PDF file and extracts the text from it.\n",
    "        \n",
    "        Parameters:\n",
    "        path : str\n",
    "        The path to the PDF file that needs to be parsed.\n",
    "        \n",
    "        Returns:\n",
    "        text : str\n",
    "        The extracted text from the PDF file.\n",
    "        \"\"\"\n",
    "        # print(\"Parse\")\n",
    "        try:\n",
    "            doc = fitz.open(path)\n",
    "            text = \"\"\n",
    "            for page_num in range(min(1,len(doc))):\n",
    "                page = doc.load_page(page_num)  # Load page\n",
    "                text += page.get_text() + \"\\n\"  # Extract text from page\n",
    "\n",
    "            doc.close()\n",
    "            \n",
    "            # Clean text\n",
    "            clean_text = \"\\n\".join([line.strip() for line in text.splitlines() if line.strip()])\n",
    "            return clean_text\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\",file=logs,flush=True)\n",
    "            return f\"An error occurred: {e}\"\n",
    "            \n",
    "class AskExpert(Tool):\n",
    "    \"\"\"\n",
    "    This tool can by used to analyse and process text and also summnerize text.\n",
    "    The tool asks a question to an expert and returns the answer.\n",
    "    \n",
    "    Methods:\n",
    "    run(query):\n",
    "    Asks the question to the expert and returns the answer.\n",
    "    \"\"\"\n",
    "    def run(self, query):\n",
    "        \"\"\"\n",
    "        Asks the question to the expert and returns the answer.\n",
    "        Parameters:\n",
    "        query : str\n",
    "        The question that needs to be asked to the expert.\n",
    "        Returns:\n",
    "        answer : str\n",
    "        The answer provided by the expert.\n",
    "        \"\"\"\n",
    "        # print(\"AskQuestion\")\n",
    "        try:\n",
    "            client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                                messages=[\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": query,\n",
    "                                    }\n",
    "                                ],\n",
    "                                model=\"llama3-70b-8192\",\n",
    "                            )\n",
    "            return chat_completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\",file=logs,flush=True)\n",
    "            return f\"An error occurred: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted abstract: With the rise of marine exploration, underwater imaging has gained significant attention as a research topic. Under-water video enhancement has become crucial for real-time computer vision tasks in marine exploration. However, most existing methods focus on enhancing individual frames and neglect video temporal dynamics, leading to visually poor enhancements. Furthermore, the lack of ground-truth references limits the use of abundant available underwater video data in many applications.\n",
      "Error code: 413 - {'error': {'message': 'Request too large for model `llama3-70b-8192` in organization `org_01jf5mp65dew4tbw71ektwjwkq` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6142, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Retrying...\n",
      "Error code: 413 - {'error': {'message': 'Request too large for model `llama3-70b-8192` in organization `org_01jf5mp65dew4tbw71ektwjwkq` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6142, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Retrying...\n",
      "Error code: 413 - {'error': {'message': 'Request too large for model `llama3-70b-8192` in organization `org_01jf5mp65dew4tbw71ektwjwkq` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 6142, please reduce your message size and try again. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Retrying...\n",
      "Max retries exceeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(\n",
    "    client=client,\n",
    "    model=\"llama3-70b-8192\",\n",
    "    tools=[\n",
    "        Finish(),\n",
    "        AskUser(),\n",
    "        FetchPaper(),\n",
    "        Parse(),\n",
    "        AskExpert()\n",
    "    ],\n",
    "    max_steps=10,\n",
    ")\n",
    "agent(\"Summerize the paper with arxiv id 2411.05886\")\n",
    "while True:\n",
    "    query = input()\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    agent(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
